import streamlit as st
import pickle
from data_preparation import preprocess_data
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from datetime import datetime

# Load the model and vectorizer
@st.cache_resource
def load_model():
    with open('../models/model.pkl', 'rb') as f:
        model = pickle.load(f)
    with open('../models/vectorizer.pkl', 'rb') as f:
        vectorizer = pickle.load(f)
    return model, vectorizer

def send_email_alert(suspicious_text, probability, keywords):
    try:
        # Email configuration
        sender_email = "ashrayujpandey@gmail.com"
        sender_password = "ihziqmajzljpyger"
        receiver_email = "ashrayujpandey@gmail.com"

        # Debug print
        st.write("Attempting to send email...")

        # Create message
        msg = MIMEMultipart()
        msg['Subject'] = '‚ö†Ô∏è Suspicious Content Alert'
        msg['From'] = sender_email
        msg['To'] = receiver_email

        # Email body
        body = f'''
        ‚ö†Ô∏è SUSPICIOUS CONTENT DETECTED ‚ö†Ô∏è

        Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

        Suspicious Content:
        {suspicious_text}

        Confidence Level: {probability:.2%}

        Keywords Detected: {', '.join(keywords) if keywords else 'None'}

        This is an automated alert generated by the Terrorism Content Detection System.
        Please review the content and take appropriate action if necessary.
        '''

        msg.attach(MIMEText(body, 'plain'))

        try:
            # Create SMTP session with explicit debugging
            server = smtplib.SMTP_SSL('smtp.gmail.com', 465)
            st.write("Connected to SMTP server...")
            
            # Try login
            server.login(sender_email, sender_password)
            st.write("Login successful...")
            
            # Send email
            server.send_message(msg)
            st.write("Email sent successfully...")
            
            # Close connection
            server.quit()
            return True

        except smtplib.SMTPAuthenticationError as auth_error:
            st.error(f"Authentication failed: {str(auth_error)}")
            return False
        except smtplib.SMTPException as smtp_error:
            st.error(f"SMTP error occurred: {str(smtp_error)}")
            return False

    except Exception as e:
        st.error(f"Failed to send email: {str(e)}")
        return False

def predict_text(text, model, vectorizer):
    # Preprocess the text
    processed_text = preprocess_data(text)
    
    # Transform using vectorizer
    text_tfidf = vectorizer.transform([processed_text])
    
    # Get base prediction
    prediction = model.predict(text_tfidf)[0]
    base_probability = model.predict_proba(text_tfidf)[0][1]
    
    # Get keywords
    keywords = []
    text_lower = text.lower()
    
    # Check for keywords with context
    high_risk_keywords = [
        'attack', 'bomb', 'explosive', 'jihad', 'martyr', 'kill', 'murder',
        'execute', 'assassinate', 'hijack', 'detonate', 'gunfire', 'suicide',
        'terrorist', 'massacre', 'behead', 'firebomb', 'sabotage', 'annihilate'
    ]
    
    medium_risk_keywords = [
        'radical', 'extremist', 'caliphate', 'militant', 'infidel', 'hostage',
        'violence', 'war', 'strike', 'retaliate', 'ambush', 'sniper', 'target',
        'threat', 'hate', 'purge', 'rebel', 'recruit', 'holy war', 'weapons',
        'bloodshed', 'radicalize', 'execution', 'uprising'
    ]
    
    # Safe context words
    safe_contexts = [
        'movie', 'game', 'film', 'play', 'book', 'story', 'novel', 'fiction',
        'documentary', 'history', 'news', 'report', 'study', 'research',
        'analysis', 'review', 'entertainment', 'video', 'series', 'show'
    ]
    
    # Count keyword occurrences
    high_risk_count = sum(1 for word in high_risk_keywords if word in text_lower)
    medium_risk_count = sum(1 for word in medium_risk_keywords if word in text_lower)
    safe_context_count = sum(1 for word in safe_contexts if word in text_lower)
    
    # Collect found keywords
    keywords = [word for word in high_risk_keywords if word in text_lower]
    keywords.extend([word for word in medium_risk_keywords if word in text_lower])
    
    # Adjust probability based on keyword analysis
    threat_score = (high_risk_count * 0.3) + (medium_risk_count * 0.15)
    safe_score = safe_context_count * 0.2
    
    # Calculate final probability
    adjusted_probability = base_probability + threat_score - safe_score
    
    # Ensure probability is between 0 and 1
    final_probability = max(0, min(1, adjusted_probability))
    
    # Set threshold for suspicious content
    THREAT_THRESHOLD = 0.5
    
    # Additional context checks
    common_safe_phrases = [
        'i like', 'i love', 'favorite', 'enjoy', 'fun', 'happy',
        'beautiful', 'wonderful', 'amazing', 'great', 'good',
        'delicious', 'tasty', 'sweet', 'nice', 'cool'
    ]
    
    # Check for safe phrases
    has_safe_phrases = any(phrase in text_lower for phrase in common_safe_phrases)
    
    # Make final prediction
    final_prediction = 0  # Default to non-suspicious
    
    if final_probability > THREAT_THRESHOLD:
        if has_safe_phrases and not keywords:
            # Override prediction if text contains safe phrases and no threat keywords
            final_prediction = 0
            final_probability = 0.2  # Set a low probability
        else:
            final_prediction = 1
    
    return final_prediction, final_probability, keywords

def main():
    st.title('Terrorism Content Detection System')
    
    # Store the analysis state
    if 'analyzed' not in st.session_state:
        st.session_state.analyzed = False
    if 'prediction' not in st.session_state:
        st.session_state.prediction = None
    if 'probability' not in st.session_state:
        st.session_state.probability = None
    if 'keywords' not in st.session_state:
        st.session_state.keywords = None
    
    st.write('''
    This application uses machine learning to detect potential terrorist content in text.
    Please enter the text you want to analyze below.
    ''')
    
    # Text input
    text_input = st.text_area('Enter text to analyze:', height=200)
    
    # Analysis button
    if st.button('Analyze'):
        if text_input:
            try:
                model, vectorizer = load_model()
                prediction, probability, keywords = predict_text(text_input, model, vectorizer)
                
                # Store results in session state
                st.session_state.analyzed = True
                st.session_state.prediction = prediction
                st.session_state.probability = probability
                st.session_state.keywords = keywords
                st.session_state.text = text_input
                
                st.write('### Results:')
                
                if prediction == 1:
                    st.error(f'‚ö†Ô∏è Potential suspicious content detected with {probability:.2%} confidence')
                else:
                    st.success(f'‚úÖ No suspicious content detected ({(1-probability):.2%} confidence)')
                
                # Show probability gauge
                st.write('### Probability of Suspicious Content:')
                st.progress(float(probability))
                
                # Show keywords if any were found
                if keywords:
                    st.write('### Detected Keywords:')
                    st.write(', '.join(keywords))
                
            except Exception as e:
                st.error(f'Error analyzing text: {str(e)}')
        else:
            st.warning('Please enter some text to analyze.')
    
    # Separate report button
    if st.session_state.analyzed and st.session_state.prediction == 1:
        if st.button('üìß Report This Content', key='report_button'):
            st.write("Attempting to send report...")
            if send_email_alert(st.session_state.text, 
                              st.session_state.probability, 
                              st.session_state.keywords):
                st.success('''
                ‚úÖ Alert sent successfully!
                An email has been sent to the monitoring team for review.
                ''')
                
                # Show what was reported
                with st.expander('View Report Details'):
                    st.write('**Reported Content:**')
                    st.write(st.session_state.text)
                    st.write('**Detection Confidence:**', f"{st.session_state.probability:.2%}")
                    if st.session_state.keywords:
                        st.write('**Keywords Detected:**', ', '.join(st.session_state.keywords))
    
    st.sidebar.title('About')
    st.sidebar.info('''
    This application demonstrates the use of machine learning for suspicious content detection.
    It uses text classification to identify potential concerning content in text.
    
    **Note**: This system is for research and demonstration purposes only.
    ''')
    
    # Add guidelines
    st.sidebar.title('Guidelines')
    st.sidebar.info('''
    **The system analyzes:**
    - Text content and context
    - Presence of concerning keywords
    - Overall message intent
    
    **Remember:**
    - This is an automated system
    - Results are probabilistic
    - Human review is recommended
    ''')

if __name__ == '__main__':
    main()
